{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d1c8654",
   "metadata": {},
   "source": [
    "# Introduction to Python\n",
    "\n",
    "\n",
    "Python is a high-level, interpreted programming language known for its simplicity and readability. It is widely used in various domains, including web development, data analysis, text analysis, artificial intelligence, scientific computing, and more. Python's versatility and extensive library ecosystem make it a popular choice for both beginners and experienced developers.\n",
    "\n",
    "\n",
    "## Example: Hello World in Python\n",
    "```python\n",
    "print(\"Hello, World!\")\n",
    "```\n",
    "\n",
    "## Applications of Python\n",
    "| **Category** | **Libraries/Tools** | **Example Use Case**|\n",
    "| -------------|---------------------|---------------------|\n",
    "| Web Development | Django, Flask | Build a blog, dashboard, or interactive visualization|\n",
    "| Data Science | pandas, NumPy, Matplotlib | Analyze, clean, and visualize quanitative or qualitative data|\n",
    "| Automation | os, shutil, sched | Rename a batch of files |\n",
    "| Text Analyis | spaCy, NLTK | Sentiment analysis on reviews |\n",
    "| Mapping | GeoPandas, Folium, geopy | Plot locations on an interactive map |\n",
    "| Data Management | pandas, `csv`, `xlm`, `json` | Clean and standardize metadata for a digital collection |\n",
    "| Webscraping | BeautifulSoup, Scrapy | Collect daily weather data |\n",
    "| Machine Learning | scikit-learn, TensorFlow | Classify emails as spam|\n",
    "| Data Processing/Cleaning | pandas, regex, `csv` | Clean historical census data for analysis |\n",
    "| Education |  Jupyter | Provide introductory material in an easy format |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e8b40c",
   "metadata": {},
   "source": [
    "## Libraries \n",
    "\n",
    "Libraries are collections of code, that you can essentially \"check-out\" to use. Once you import the library, you call different modules or functions within that library to perform specific tasks. \n",
    "\n",
    "<img src=\"img/python-library.jpg\" alt=\"Python Library Example\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4224bfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here we're going to import a couple of libraries that we will use in our codes. \n",
    "## Notice that we are using the \"as\" keyword to give aliases to the libraries - this is a common practice to make the code cleaner and easier to read.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17657923",
   "metadata": {},
   "source": [
    "## Data Types\n",
    "\n",
    "Data types are the kinds of values you can use in Python. Every value in Python has a type and unlike other many other languages you do not have to explicitly set these types. However because of that you have to be diligent to keep track of the types as you go. \n",
    "\n",
    "Each type will have it's own set of functions and expressions that can performed. \n",
    "\n",
    "### Basic Data Types\n",
    "| Type | Example | Description |\n",
    "|------|---------|-------------|\n",
    "| `int`| 42, -2, 3244235 | Whole numbers (positive or negative) |\n",
    "| `float` | 3.193727, 0.55, -2423.34243 | Decimal numbers |\n",
    "| `str` | \"hello\", \"hello, world\", \"h\" | Text (string of characters) | \n",
    "| `bool` | True, False | Boolean values (logic, conditionals) | "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0fe058",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now let's go through some examples of these data types \n",
    "\n",
    "## number of pages - ints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa636d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## number of pages - floats \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae18aed",
   "metadata": {},
   "source": [
    "We can also do other types of mathematics: \n",
    "\n",
    "| Operation | Symbol | Example | Output |\n",
    "|------|---------|-------------|--------|\n",
    "| Addition | `+` | `1 + 1`| `2`|\n",
    "| Subtraction |  `-` | `2 - 1` | `1`|\n",
    "| Multiplication | `*` | `2 * 2` | `4`|\n",
    "| Division | `/` | ` 3 / 1 ` | `3`|\n",
    "| Division (floor) | `//` | `10 // 3`| `3`|\n",
    "| Remainder | `%` | `10 % 3` | `1`|\n",
    "| Exponent | `**` | ` 3 ** 2` | `9`| \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cd163e",
   "metadata": {},
   "source": [
    "**Try it Yourself**: Let's combine what we know about variable names, expressions, and int/floats to create a more complex string of commands to figure out the cost of book. Let's say you're buying a book from a independent bookstore and there's both a sales tax of 5% and a shipping fee of 12%. Let's first figure out the sales tax and then the shipping fee if the item is $27 before calculating the total cost. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a2942a",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_cost = ... \n",
    "sales_tax = ...\n",
    "shipping_fee = ...\n",
    "total_cost = ...\n",
    "print(total_cost, sales_tax, shipping_fee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8378ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "## We can also convert numbers to strings\n",
    "num_pages_str = ...\n",
    "print(num_pages_str, type(num_pages_str))\n",
    "print(num_pages, type(num_pages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fbbfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now let's look more at strings \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad86049",
   "metadata": {},
   "outputs": [],
   "source": [
    "## we can do a couple different things with strings, like finding their length\n",
    "title_length = ...\n",
    "\n",
    "## or we can add strings together\n",
    "author_name = \"Douglas Adams\" \n",
    "full_title = ...\n",
    "print(full_title)\n",
    "\n",
    "## we can also strip characters from strings, select specific words or characters, and convert them to uppercase or lowercase\n",
    "stripped_title = ...\n",
    "print(stripped_title)\n",
    "\n",
    "last_word = ...\n",
    "print(last_word)\n",
    "\n",
    "uppercase_title = ...\n",
    "print(uppercase_title)\n",
    "\n",
    "lowercase_title = ...\n",
    "print(lowercase_title)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d018b50",
   "metadata": {},
   "source": [
    "### Collection Data Types\n",
    "| Type | Example | Description |\n",
    "|------|---------|-------------|\n",
    "| `list`| `[1, 2, 3]` or `[99, 'hello', False]` | Ordered, changeable sequence |\n",
    "| `dict` | `{\"key\":\"value\"}` or `{\"Ada\":['Librarian', 42, \"Carpenter\"]}` | Key-value pairs |\n",
    "| `tuple` | `(1, 2, 3, 3)` | Ordered, unchangeable sequence | \n",
    "| `set` | `set(1, 2, 3)` | Unordered collection of unique values | "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfa6749",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now let's look at lists, which are a way to store multiple items in a single variable\n",
    "book_titles = [\"The Hitchhiker's Guide to the Galaxy\", \n",
    "               \"1984\", \n",
    "               \"To Kill a Mockingbird\", \n",
    "               \"Pride and Prejudice\"]\n",
    "print(book_titles)\n",
    "print(type(book_titles))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ebc265",
   "metadata": {},
   "outputs": [],
   "source": [
    "## we can select specific items from a list using their index (Python always starts counting at 0)\n",
    "first_book = ...\n",
    "print(first_book)\n",
    "\n",
    "## an easy way to get the last item is to use a negative index\n",
    "last_book = ...\n",
    "print(last_book)\n",
    "\n",
    "## we can also add items to a list using append()\n",
    "...\n",
    "print(book_titles)\n",
    "\n",
    "## or we can remove items using remove()\n",
    "...\n",
    "print(book_titles)\n",
    "\n",
    "## we can also sort lists\n",
    "...\n",
    "print(book_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04576db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## now let's look at dictionaries, which are a way to store key-value pairs\n",
    "\n",
    "book_info = {\n",
    "    \"title\": \"The Hitchhiker's Guide to the Galaxy\",\n",
    "    \"author\": \"Douglas Adams\",\n",
    "    \"pages\": 216,\n",
    "    \"published_year\": 1979\n",
    "}\n",
    "...\n",
    "...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2535d501",
   "metadata": {},
   "outputs": [],
   "source": [
    "## we can access specific values in a dictionary using their keys\n",
    "title = ...\n",
    "print(title)\n",
    "\n",
    "## we can also add new key-value pairs to a dictionary\n",
    "...\n",
    "print(book_info)\n",
    "\n",
    "## or we can remove key-value pairs using the del keyword\n",
    "...\n",
    "print(book_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c972ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## we can have dictionaries within dictionaries, which is useful for more complex data structures\n",
    "book_collection = {\n",
    "    24234: {\n",
    "        \"title\": \"The Hitchhiker's Guide to the Galaxy\",\n",
    "        \"author\": \"Douglas Adams\",\n",
    "        \"pages\": 216\n",
    "    },\n",
    "    24235: {\n",
    "        \"title\": \"1984\",\n",
    "        \"author\": \"George Orwell\",\n",
    "        \"pages\": 368\n",
    "    }\n",
    "}\n",
    "print(book_collection)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3cad32",
   "metadata": {},
   "outputs": [],
   "source": [
    "## we can access specific books in the collection using their keys\n",
    "book_id = 24235\n",
    "book_details = ...\n",
    "print(book_details)\n",
    "\n",
    "## we can also access specific values within the nested dictionary\n",
    "book_title = ...\n",
    "print(book_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a7f394",
   "metadata": {},
   "source": [
    "## Loops and Conditionals \n",
    "\n",
    "### Conditionals or Comparisons\n",
    "Sometimes we want to be able to compare different variables or expressions. This could be to find matching amounts/text or perhaps you want to identify when a specifc number rises above a certain threshold. We can do this through using comparison statements. \n",
    "\n",
    "Reminder:  Booleans - represent either True or False often in logic or conditional statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c25d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "## let's look at some examples of using conditional statements \n",
    "\n",
    "...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cc0d9e",
   "metadata": {},
   "source": [
    "### Methods of comparison \n",
    "\n",
    "| Comparison | Operator | \n",
    "|------|---------|\n",
    "| Less than | `<` |\n",
    "| Greater than | `>` | \n",
    "| Less than or equal to | `<=` | \n",
    "| Greater than or equal to | `>=` |\n",
    "| Equal | `==` |\n",
    "| Not equal | `!=` |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f81965",
   "metadata": {},
   "outputs": [],
   "source": [
    "## We can combine if statements with conditional operators to help move through the code \n",
    "...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93866991",
   "metadata": {},
   "outputs": [],
   "source": [
    "## we can also combine multiple conditions together using keywords like 'and', 'or', and 'not' \n",
    "if book1_pages > 200 and book2_pages > 300:\n",
    "    print(\"Both books have a significant number of pages.\")\n",
    "else:\n",
    "    print(\"At least one book does not have a significant number of pages.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c2c232",
   "metadata": {},
   "source": [
    "### Loops (Automation)\n",
    "\n",
    "Sometimes we will want to repeat the exact same task again and again. In python, loops allow us to create this type of automations to repeat tasks efficiently. The most common types of loops are using *for* and *while*. A for loop is often used to iterate over a sequence such as a list executing the same code for each element in the list. A while loop continues to run as long as a specified condition remains true. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afedd71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## The final piece is to look at loops which allows us to iterate over our collection data types\n",
    "\n",
    "## Let's start with a simple for loop to iterate over a list of book titles\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43ae060",
   "metadata": {},
   "outputs": [],
   "source": [
    "## we can also use the range function to iterate over a list by the index values \n",
    "for i in range(len(book_titles)):\n",
    "    print(f\"Book {i + 1}: {book_titles[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254acf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## now let's combine loops and conditional statements\n",
    "for ... in ...:\n",
    "    if ...:\n",
    "        print(f\"Book ID {book_id} has more than 300 pages: {details['title']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7862bd",
   "metadata": {},
   "source": [
    "## Tables\n",
    "\n",
    "When working with data in Python, we often organize it in a table with rows and columns. The most powerful tool for working with tables is a library called `pandas` which makes it easy to load data from csv and Excel files, view and explore datasets, filter and clean data, calculate statistics, and prepare data for visualization. \n",
    "\n",
    "Tables are stored in an object called a DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a68e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "## We're going to start by using Pandas to read in a CSV file that contains metadata about novels \n",
    "df = pd.read_csv('top-500-novels-metadata_2025-01-11.csv')  ## https://www.responsible-datasets-in-context.com/posts/top-500-novels/top-500-novels.html?tab=data-essay#whats-in-the-data \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b20c116",
   "metadata": {},
   "outputs": [],
   "source": [
    "## You can double click on the table output above to hide or collapse it. \n",
    "## Notice how the table hides the middle rows and columns to make it easier to read?\n",
    "## Let's change that so we can see all the columns in the DataFrame.\n",
    "with pd.option_context('display.max_columns', None):\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31129a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "## we can do some basic analyis on the dataset \n",
    "print(df.shape)  # Get the number of rows and columns in the DataFrame\n",
    "print(df.info())  # Get information about the DataFrame, including data types and non-null counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0be95a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.describe())  # Get summary statistics for numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcae4a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8489f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## We can select specific columns from the DataFrame by using their names\n",
    "...\n",
    "\n",
    "## We can also select multiple columns by passing a list of column names\n",
    "df[['title', 'author', 'pub_year']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbeb255",
   "metadata": {},
   "outputs": [],
   "source": [
    "## We can filter the DataFrame based on specific conditions\n",
    "filtered_df = df[...]  # Select rows where the year is greater than 2000\n",
    "print(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549722c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## We can calculate statistics on specific columns\n",
    "avg_holdings = df['oclc_holdings'].mean()  # Calculate the average number of OCLC holdings\n",
    "print(avg_holdings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57db62d",
   "metadata": {},
   "source": [
    "**Try It Yourself**: Select a column and try to find out some basic summary statistics such as the minimum, maximum, median, mean, and mode values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3468cab9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "987f4788",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "\n",
    "Now let's think about how we might continue to explore this dataset using visualizations. We're going to be using a combination of pandas' built-in plotting functions and the matplotlib library. \n",
    "\n",
    "Matplotlib is one of the most powerful and widely used libraries for creating visualizations in Python. While other libraries such as seaborn and plotly offer stylish and interactive plots with less code, matplotlib gives you the ability to have fine-grained control over every aspect of a figure. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672402ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example 1: Histograms - Used for showing the distribution of single numerical variable \n",
    "\n",
    "df.hist('gr_avg_rating', bins=20, edgecolor='black')  ## here is where we actually create the histogram\n",
    "plt.xlabel('Average Rating')  ## here we label the x-axis\n",
    "plt.ylabel('Frequency')  ## here we label the y-axis\n",
    "plt.title('Distribution of Average Goodreads Ratings')  ## here we give it a title "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8514f73c",
   "metadata": {},
   "source": [
    "Now let's look at a more complicated example. We have several columns that are categorical. We might want to look at the comparison between these columns such as the example below where we examine the difference in Goodreads averages for books in the public domain versus books not in the public domain. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a507146",
   "metadata": {},
   "outputs": [],
   "source": [
    "notPublic = df[(df['pg_eng_url'] == 'NA_not-pub-domain') | (df['pg_eng_url'] == 'unavailable')]\n",
    "Public = df[df['pg_eng_url'] != 'NA_not-pub-domain']\n",
    "\n",
    "notPublic['PublicDomain'] = 'Not Public Domain'\n",
    "Public['PublicDomain'] = 'Public Domain'\n",
    "updated_table_domain = pd.concat([notPublic, Public])\n",
    "\n",
    "plt.hist(notPublic['gr_avg_rating'], bins=20, edgecolor='black', alpha=0.5, label='Not Public Domain', color = 'red')\n",
    "plt.hist(Public['gr_avg_rating'], bins=20, edgecolor='black', alpha=0.5, label='Public Domain', color = 'blue')\n",
    "plt.legend()\n",
    "plt.xlabel('Goodreads Average Rating')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Goodreads Average Ratings for Public Domain vs Not Public Domain Novels')\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34e2b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## we can also do this using seaborn, which is a library built on top of matplotlib that makes it easier to create complex visualizations\n",
    "import seaborn as sns\n",
    "sns.histplot(data=df, x='gr_avg_rating', hue = 'pg_eng_url', bins=20, kde=True, color='blue', edgecolor='black')\n",
    "plt.xlabel('Average Goodreads Rating')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Average Goodreads Ratings')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f3bbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=updated_table_domain, x='gr_avg_rating', hue = 'PublicDomain', bins=20, kde=True, color='blue', edgecolor='black')\n",
    "plt.xlabel('Average Goodreads Rating')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Average Goodreads Ratings')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be4f46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example 2: Scatter Plots - Used for showing the relationship between two numerical variables \n",
    "\n",
    "plt.scatter(df['pub_year'], df['gr_avg_rating'], alpha=0.5, color='blue')\n",
    "plt.xlabel('Publication Year')\n",
    "plt.ylabel('Average Goodreads Rating')\n",
    "plt.title('Publication Year vs Average Goodreads Rating')\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bc6165",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example 3: Line Plots - Used for showing trends over time or ordered categories\n",
    "\n",
    "plt.plot(df['pub_year'], df['gr_avg_rating'], marker='o', linestyle='-', color='blue', alpha=0.5)\n",
    "plt.xlabel('Publication Year')  \n",
    "plt.ylabel('Average Goodreads Rating')\n",
    "plt.title('Publication Year vs Average Goodreads Rating')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a826b21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## we can see that this doesn't quite work as expected because the publication years are not sorted and are not unique\n",
    "## so let's try to fix that\n",
    "sorted_df = df.sort_values(by='pub_year')  # Sort the DataFrame by publication year\n",
    "plt.plot(sorted_df['pub_year'], sorted_df['gr_avg_rating'], marker='o', linestyle='-', color='blue', alpha=0.5)\n",
    "plt.clf()\n",
    "\n",
    "## still not quite what we want so let's group the data by publication year and get an average\n",
    "grouped_df = df.groupby('pub_year')['gr_avg_rating'].mean().reset_index()  # Group by publication year and calculate the average rating\n",
    "plt.plot(grouped_df['pub_year'], grouped_df['gr_avg_rating'], linestyle='-', color='blue', alpha=0.5)\n",
    "plt.xlabel('Publication Year')\n",
    "plt.ylabel('Average Goodreads Rating')\n",
    "plt.title('Average Goodreads Rating by Publication Year')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dbe700",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example 4: Bar Plots - Used for comparing categorical data\n",
    "grouped_languages = df.groupby('orig_lang')['gr_avg_rating'].mean().reset_index()  # Group by original language and calculate the average rating\n",
    "grouped_languages = grouped_languages.sort_values(by='gr_avg_rating', ascending=False)  # Sort by average rating\n",
    "\n",
    "plt.figure(figsize=(12, 6))  # Set the figure size\n",
    "plt.bar(grouped_languages['orig_lang'], grouped_languages['gr_avg_rating'], color='blue', alpha=0.7)\n",
    "plt.xlabel('Original Language')\n",
    "plt.ylabel('Average Goodreads Rating')\n",
    "plt.title('Average Goodreads Rating by Original Language')\n",
    "plt.xticks(rotation=45)  # Rotate x-axis labels for better readability\n",
    "plt.tight_layout()  # Adjust layout to prevent overlap\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796d0b22",
   "metadata": {},
   "source": [
    "**Try it Yourself**: Pick a column or a series of columns to explore. Try to visualize your selected data - is there any obstacles you encountered? Is the data in a form that you have to alter or manipulate or filter? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7a6877",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a48708c4",
   "metadata": {},
   "source": [
    "## Application: Text Analysis\n",
    "\n",
    "Now let's put this all together. \n",
    "1. First scroll through the pubicly available options as listed in the cell below. Pick one to fetch from Project Gutenberg. \n",
    "2. Using the library `fetch` we will webscrape the entire text to save as an object. \n",
    "3. Clean the text to remove the header and footer. \n",
    "4. Extract all the words in lowercase format. \n",
    "5. Examine the frequency of words via two different types of visualizations. \n",
    "6. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cb53b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 1: Pick a title to analyze. \n",
    "for title in Public['title']:\n",
    "    print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c2fedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 2: Pull the data for the book you picked. \n",
    "\n",
    "import requests ## library for making HTTP requests\n",
    "\n",
    "url = Public[Public['title'] == ...]['pg_eng_url'].values[0]  ## Get the URL for your chosen book \n",
    "response = requests.get(url)  ## Make a GET request to the URL\n",
    "if response.status_code == 200:  ## Check if the request was successful\n",
    "    print(\"Successfully retrieved the book page.\")\n",
    "else:\n",
    "    print(f\"Failed to retrieve the book page. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31377499",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.text[:1000]  ## Print the first 500 characters of the response text to see the content of the page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc16f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 3: Clean the data to remove the header and footer from the response text \n",
    "\n",
    "## remove the header and footer from the response text \n",
    "start = response.text.find(\"*** START OF THE PROJECT GUTENBERG EBOOK\")  ## Find the start of the book text\n",
    "end = response.text.find(\"*** END OF THE PROJECT GUTENBERG EBOOK\")  ## Find the end of the book text\n",
    "cleaned_text = response.text[start:end]  ## Extract the book text between the start and end markers\n",
    "\n",
    "cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca4f1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 4: Process the cleaned text to extract words \n",
    "\n",
    "## now let's make everything lowercase and remove any punctuation \n",
    "import re ## library for regular expressions\n",
    "words = re.findall(r'\\b[a-z]+\\b', cleaned_text.lower())\n",
    "\n",
    "print(words[:100])  ## Print the first 100 words to see the cleaned text\n",
    "print(len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f271bb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 5: Analyze the frequency of words in the text \n",
    "\n",
    "## let's take a look at the most common words in the text \n",
    "\n",
    "from collections import Counter ## library for counting hashable objects \n",
    "\n",
    "word_counts = Counter(words)  ## count the number of times each word appears in the text\n",
    "word_counts.most_common(10) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195b1ea9",
   "metadata": {},
   "source": [
    "This isn't intersting though - those are all filler words!  Is there a way to easily remove these words from our analysis so that we can what words are really representative of this text? There are several libraries that you can use to do so such nltk and spaCy - here we're going to be using nltk which is a natural language processing library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b679c8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import nltk  ## library for natural language processing\n",
    "from nltk.corpus import stopwords  ## library for stop words\n",
    "\n",
    "nltk.download('stopwords')  ## Download the stop words list if you haven't already\n",
    "stop_words = set(stopwords.words('english'))  ## Get the set of English stop words\n",
    "\n",
    "for word in list(word_counts.keys()):\n",
    "    if word in stop_words:  ## Check if the word is a stop word\n",
    "        del word_counts[word]  ## Remove the stop word from the counts\n",
    "\n",
    "word_counts.most_common(10)  ## Print the most common words after removing stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d7d0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_words = word_counts.most_common(10)  ## Get the most common words\n",
    "words, counts = zip(*most_common_words)  ## Unzip the words and counts into separate lists\n",
    "\n",
    "plt.bar(words, counts, color='blue')\n",
    "plt.xlabel('Words')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Most Common Words')\n",
    "plt.xticks(rotation=45)  ## Rotate x-axis labels for better readability\n",
    "plt.tight_layout()  ## Adjust layout to prevent overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3610448d",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from wordcloud import WordCloud  ## library for generating word clouds\n",
    "except:\n",
    "    %pip install wordcloud \n",
    "    from wordcloud import WordCloud\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242979da",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualisation Number 2: Word Cloud \n",
    "\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(word_counts)  ## Generate a word cloud from the word counts\n",
    "plt.figure(figsize=(10, 5))  ## Set the figure size\n",
    "plt.imshow(wordcloud, interpolation='bilinear')  ## Display the word cloud\n",
    "plt.axis('off')  ## Turn off the axis\n",
    "\n",
    "## Optional Save the figure as an image file \n",
    "plt.savefig('name.png', bbox_inches='tight', dpi=300)  ## Save the figure as a PNG file\n",
    "plt.show()  ## Show the word cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed7c79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 6: Perform sentiment analysis on the text \n",
    "\n",
    "nltk.download('vader_lexicon')  ## Download the VADER lexicon for sentiment analysis\n",
    "\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer  ## library for sentiment analysis\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()  ## Create a SentimentIntensityAnalyzer object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c43fd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## example Sentence \n",
    "sentence = \"The Wizard of Oz is a wonderful story.\"\n",
    "sentiment_scores = sia.polarity_scores(sentence)  ## Get the sentiment scores for the sentence\n",
    "print(sentiment_scores)  ## Print the sentiment scores for the sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d01c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's extract the sentences for your book \n",
    "\n",
    "sentences = nltk.sent_tokenize(cleaned_text)  ## split the cleaned text into sentences using NLTK's sentence tokenizer\n",
    "print(sentences[:5])  ## Print the first 5 sentences to see the tokenized sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ea3c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sentence(sentence):\n",
    "    \"\"\"Clean a sentence by removing punctuation and converting to lowercase.\"\"\"\n",
    "    # Remove asterisks, underscores, and other decorative symbols\n",
    "    cleaned_sentence = re.sub(r'[_*#<>+=\\\\/\\[\\]{}|]', '', sentence)\n",
    "\n",
    "\n",
    "    # Replace multiple newlines or spaces with single space\n",
    "    cleaned_sentence = re.sub(r'\\s+', ' ', cleaned_sentence)\n",
    "\n",
    "    # Remove weird characters (non-ASCII)\n",
    "    cleaned_sentence = cleaned_sentence.encode('ascii', errors='ignore').decode()\n",
    "\n",
    "    # Strip leading/trailing spaces\n",
    "    cleaned_sentence = cleaned_sentence.strip()\n",
    "\n",
    "    return cleaned_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec95ff9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_sentences = []\n",
    "\n",
    "for sentence in sentences:\n",
    "    cleaned_sentences.append(clean_sentence(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a42e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_sentences[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4ab941",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for sentence in cleaned_sentences:\n",
    "    sentiment_scores = sia.polarity_scores(sentence)  ## Get the sentiment scores for the sentence\n",
    "    results.append((sentence, sentiment_scores['compound']))  ## Append the sentiment scores to the results list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7436d68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## visualize the sentiment scores \n",
    "\n",
    "df = pd.DataFrame(results, columns=['Sentence', 'Score'])\n",
    "\n",
    "plt.plot(df['Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ecb8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This makes it hard to see any overall trends so let's calculate the average sentiment score fo every 50 sentences. \n",
    "\n",
    "## create a dictionary to store the averages \n",
    "avgScores = {}\n",
    "\n",
    "## create counter and avgValue variables to keep track \n",
    "counter = 0 \n",
    "avgValue = 0\n",
    "\n",
    "## loop through the results \n",
    "for i in range(len(results)):\n",
    "    avgValue += results[i][1]  ## add the sentiment score to the avgValue\n",
    "    counter += 1  ## increment the counter\n",
    "\n",
    "    ## when we're ready to go to the next bin, we first calculate the average for the current bin, and reset the counter and avgValue \n",
    "    if counter == 50:\n",
    "        avgScores[i // 50] = avgValue / 50\n",
    "        counter = 0\n",
    "        avgValue = 0\n",
    "\n",
    "plt.plot(list(avgScores.keys()), list(avgScores.values()), marker='o', linestyle='-', color='blue', alpha=0.5)\n",
    "plt.xlabel('Sentence Bins (Every 50 Sentences)')\n",
    "plt.ylabel('Average Sentiment Score')\n",
    "plt.title('Average Sentiment Score of \"The Wizard of Oz\" by Sentence Bins')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f76ab5",
   "metadata": {},
   "source": [
    "### Congratulations you've finished up the introduction to python tutorial!  \n",
    "\n",
    "If you're interested in working through some other text analysis examples or challenges: \n",
    "\n",
    "1. Create a heatmap of word frequencies by chapter. \n",
    "2. Test whether there's a difference in sentiment for shorter sentences versus longer sentences. What built-in function could you use to calculate the length of the sentence?  How might you modify your existing code to add sentence length as a variable?\n",
    "3. Try topic modeling to identify what words cluster together using scikit-learn. \n",
    "\n",
    "You can also check out the numerous Constellate tutorials available (for a limited time!). Including but not limited to:\n",
    "- Significant Terms Analysis\n",
    "- Data Visualization \n",
    "- Building a language model\n",
    "- Sentiment Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12a39f9",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
